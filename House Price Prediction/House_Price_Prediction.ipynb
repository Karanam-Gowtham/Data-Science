{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32414dec",
   "metadata": {},
   "source": [
    "# House Price Prediction - Complete Analysis\n",
    "A comprehensive data analysis and machine learning project for predicting house prices using the Ames Housing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa738516",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f49a1e6",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "Loading and cleaning the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae474998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Training data\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11b0311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic info\n",
    "print(\"Data Info:\")\n",
    "print(df.info())\n",
    "print(\"\\nMissing values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4703ffc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates\n",
    "df.drop_duplicates(inplace=True)\n",
    "print(\"After removing duplicates:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb75b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate numeric and categorical columns\n",
    "numeric_cols = []\n",
    "categorical_cols = []\n",
    "\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == \"object\":\n",
    "        categorical_cols.append(col)\n",
    "    else:\n",
    "        numeric_cols.append(col)\n",
    "\n",
    "print(\"Numeric columns:\", len(numeric_cols))\n",
    "print(numeric_cols)\n",
    "print(\"\\nCategorical columns:\", len(categorical_cols))\n",
    "print(categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb79fda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values\n",
    "# Numeric: mean, Categorical: mode\n",
    "for col in df.columns:\n",
    "    if df[col].dtype != \"object\":\n",
    "        if df[col].isnull().sum() > 0:\n",
    "            df[col] = df[col].fillna(df[col].mean())\n",
    "    else:\n",
    "        if df[col].isnull().sum() > 0:\n",
    "            df[col] = df[col].fillna(df[col].mode()[0])\n",
    "\n",
    "print(\"Missing values after filling:\")\n",
    "print(df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9ff648",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "Encoding categorical variables and preparing features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45283e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables using LabelEncoder\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col].astype(str))\n",
    "\n",
    "print(\"Categorical columns encoded successfully!\")\n",
    "print(\"\\nData shape after preprocessing:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab990cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target variable\n",
    "y = df[\"SalePrice\"]\n",
    "X = df.drop(\"SalePrice\", axis=1)\n",
    "\n",
    "print(\"Features shape (X):\", X.shape)\n",
    "print(\"Target shape (y):\", y.shape)\n",
    "print(\"\\nTarget (SalePrice) summary:\")\n",
    "print(y.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60caf16",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "Understanding correlations and data distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364bf325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation analysis\n",
    "corr = df.corr()\n",
    "target_corr = corr['SalePrice'].sort_values(ascending=False)\n",
    "\n",
    "print(\"Top 10 features correlated with SalePrice:\")\n",
    "print(target_corr.head(10))\n",
    "\n",
    "# Features with strong correlation (>0.6 or <-0.6)\n",
    "strong_corr = target_corr[abs(target_corr) > 0.6]\n",
    "print(\"\\nFeatures with correlation > 0.6 or < -0.6:\")\n",
    "print(strong_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845e6a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature-target correlations\n",
    "plt.figure(figsize=(10, 6))\n",
    "target_corr.head(15).plot(kind='barh')\n",
    "plt.xlabel('Correlation Coefficient')\n",
    "plt.title('Top 15 Features Correlated with SalePrice')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2dc5285",
   "metadata": {},
   "source": [
    "## Train-Test Split & Feature Scaling\n",
    "Preparing data for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81700d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Train set shape:\", X_train.shape)\n",
    "print(\"Test set shape:\", X_test.shape)\n",
    "print(\"Train target shape:\", y_train.shape)\n",
    "print(\"Test target shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c227299e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Features scaled successfully!\")\n",
    "print(\"X_train_scaled shape:\", X_train_scaled.shape)\n",
    "print(\"X_test_scaled shape:\", X_test_scaled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a157f40",
   "metadata": {},
   "source": [
    "## Model Training & Evaluation\n",
    "Building and comparing multiple regression models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a0621d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "y_pred_lr = lr_model.predict(X_test_scaled)\n",
    "\n",
    "lr_mae = mean_absolute_error(y_test, y_pred_lr)\n",
    "lr_rmse = mean_squared_error(y_test, y_pred_lr) ** 0.5\n",
    "\n",
    "print(\"Linear Regression Results:\")\n",
    "print(f\"  MAE:  {lr_mae:.2f}\")\n",
    "print(f\"  RMSE: {lr_rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea08ebaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge Regression\n",
    "ridge_model = Ridge(random_state=42)\n",
    "ridge_model.fit(X_train_scaled, y_train)\n",
    "y_pred_ridge = ridge_model.predict(X_test_scaled)\n",
    "\n",
    "ridge_mae = mean_absolute_error(y_test, y_pred_ridge)\n",
    "ridge_rmse = mean_squared_error(y_test, y_pred_ridge) ** 0.5\n",
    "\n",
    "print(\"Ridge Regression Results:\")\n",
    "print(f\"  MAE:  {ridge_mae:.2f}\")\n",
    "print(f\"  RMSE: {ridge_rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36eae61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso Regression\n",
    "lasso_model = Lasso(random_state=42, max_iter=10000)\n",
    "lasso_model.fit(X_train_scaled, y_train)\n",
    "y_pred_lasso = lasso_model.predict(X_test_scaled)\n",
    "\n",
    "lasso_mae = mean_absolute_error(y_test, y_pred_lasso)\n",
    "lasso_rmse = mean_squared_error(y_test, y_pred_lasso) ** 0.5\n",
    "\n",
    "print(\"Lasso Regression Results:\")\n",
    "print(f\"  MAE:  {lasso_mae:.2f}\")\n",
    "print(f\"  RMSE: {lasso_rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deff853a",
   "metadata": {},
   "source": [
    "## RandomForest with Cross-Validation & Hyperparameter Tuning\n",
    "Advanced model selection using GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8f51cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline RandomForest with 5-fold cross-validation\n",
    "rf_baseline = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "\n",
    "cv_results = cross_validate(\n",
    "    rf_baseline, X_train_scaled, y_train, cv=5,\n",
    "    scoring=['neg_root_mean_squared_error', 'neg_mean_absolute_error'],\n",
    "    return_train_score=False\n",
    ")\n",
    "\n",
    "cv_rmse_mean = -cv_results['test_neg_root_mean_squared_error'].mean()\n",
    "cv_mae_mean = -cv_results['test_neg_mean_absolute_error'].mean()\n",
    "\n",
    "print(\"RandomForest Baseline (5-fold CV):\")\n",
    "print(f\"  CV RMSE mean: {cv_rmse_mean:.2f}\")\n",
    "print(f\"  CV MAE mean:  {cv_mae_mean:.2f}\")\n",
    "print(f\"  CV RMSE std:  {-cv_results['test_neg_root_mean_squared_error'].std():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c59356e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(\n",
    "    RandomForestRegressor(random_state=42, n_jobs=-1),\n",
    "    param_grid,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Running GridSearchCV... This may take a minute.\")\n",
    "gs.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"\\nBest parameters: {gs.best_params_}\")\n",
    "print(f\"Best CV RMSE (neg): {gs.best_score_:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f90b309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train final model with best parameters\n",
    "best_rf = gs.best_estimator_\n",
    "best_rf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions on test set\n",
    "y_pred_rf = best_rf.predict(X_test_scaled)\n",
    "\n",
    "rf_mae = mean_absolute_error(y_test, y_pred_rf)\n",
    "rf_rmse = mean_squared_error(y_test, y_pred_rf) ** 0.5\n",
    "\n",
    "print(\"RandomForest (Optimized) Test Results:\")\n",
    "print(f\"  MAE:  {rf_mae:.2f}\")\n",
    "print(f\"  RMSE: {rf_rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f74e08",
   "metadata": {},
   "source": [
    "## Model Comparison\n",
    "Comparing performance across all models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9083c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison dataframe\n",
    "results = pd.DataFrame({\n",
    "    'Model': ['Linear Regression', 'Ridge', 'Lasso', 'RandomForest'],\n",
    "    'MAE': [lr_mae, ridge_mae, lasso_mae, rf_mae],\n",
    "    'RMSE': [lr_rmse, ridge_rmse, lasso_rmse, rf_rmse]\n",
    "})\n",
    "\n",
    "results = results.sort_values('RMSE')\n",
    "print(\"Model Performance Comparison:\")\n",
    "print(results.to_string())\n",
    "print(f\"\\nBest Model: {results.iloc[0]['Model']} with RMSE: {results.iloc[0]['RMSE']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0997ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "results.sort_values('MAE').plot(x='Model', y='MAE', kind='barh', ax=axes[0], color='skyblue')\n",
    "axes[0].set_xlabel('Mean Absolute Error')\n",
    "axes[0].set_title('MAE Comparison')\n",
    "axes[0].invert_yaxis()\n",
    "\n",
    "results.sort_values('RMSE').plot(x='Model', y='RMSE', kind='barh', ax=axes[1], color='lightcoral')\n",
    "axes[1].set_xlabel('Root Mean Squared Error')\n",
    "axes[1].set_title('RMSE Comparison')\n",
    "axes[1].invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb25365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize actual vs predicted\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(y_test.values, y_test.values, color='black', linewidth=2, label='Perfect Prediction')\n",
    "plt.scatter(y_test, y_pred_lr, alpha=0.5, label='Linear', s=30)\n",
    "plt.scatter(y_test, y_pred_ridge, alpha=0.5, label='Ridge', s=30)\n",
    "plt.scatter(y_test, y_pred_lasso, alpha=0.5, label='Lasso', s=30)\n",
    "plt.scatter(y_test, y_pred_rf, alpha=0.5, label='RandomForest', s=30)\n",
    "\n",
    "plt.xlabel('Actual SalePrice')\n",
    "plt.ylabel('Predicted SalePrice')\n",
    "plt.title('Actual vs Predicted SalePrice')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13204d77",
   "metadata": {},
   "source": [
    "## Feature Importance\n",
    "Top features from the best RandomForest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abafb825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': best_rf.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"Top 15 Most Important Features:\")\n",
    "print(feature_importance.head(15).to_string())\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(10, 6))\n",
    "feature_importance.head(15).plot(x='Feature', y='Importance', kind='barh', figsize=(10, 6))\n",
    "plt.xlabel('Importance Score')\n",
    "plt.title('Top 15 Feature Importances (RandomForest)')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce1ae6b",
   "metadata": {},
   "source": [
    "## Model Saving & Deployment\n",
    "Saving the best model and scaler for future predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264105d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model and scaler\n",
    "joblib.dump(best_rf, 'best_model.joblib')\n",
    "joblib.dump(scaler, 'scaler.joblib')\n",
    "\n",
    "print(\"✓ Saved: best_model.joblib\")\n",
    "print(\"✓ Saved: scaler.joblib\")\n",
    "print(\"\\nTo use the saved model in the future:\")\n",
    "print(\"  model = joblib.load('best_model.joblib')\")\n",
    "print(\"  scaler = joblib.load('scaler.joblib')\")\n",
    "print(\"  X_new_scaled = scaler.transform(X_new)\")\n",
    "print(\"  predictions = model.predict(X_new_scaled)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4973bda4",
   "metadata": {},
   "source": [
    "## Summary & Conclusions\n",
    "- **Best Model**: RandomForest with hyperparameter tuning\n",
    "- **Test RMSE**: ~28,739 (approximately $28,739 average prediction error)\n",
    "- **Test MAE**: ~17,637 (approximately $17,637 mean absolute error)\n",
    "- **Key Features**: OverallQual, GrLivArea, GarageCars, TotalBsmtSF, and 1stFlrSF\n",
    "- **Cross-Validation**: 5-fold CV shows model stability with RMSE around 30,358\n",
    "\n",
    "The random forest model captures non-linear relationships and interactions between features effectively for this housing price prediction task."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
